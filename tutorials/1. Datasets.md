# Datasets tutorial

Datasets in nitrain help you efficiently take neuroimages and other data types from whatever source they are current in and read them into memory. This tutorial will go through all the different kinds of datasets in nitrain and how you can use them. They all generally work the same way, with the main difference being how you create them and where the data is coming from.

There are many different kinds of datasets and they are generally defined by the source or format of the data:

- BIDSDataset - data stored in a local folder with BIDS structure
- CSVDataset - data stored locally with paths to images and patient-level information stored in a single CSV file
- FolderDataset - data stored in a local folder with any structure
- GoogleCloudDataset - data stored in a Google Cloud Storage bucket folder
- MemoryDataset - data loaded into memory
- PlatformDataset - data hosted on the nitrain.dev platform

## Local storage

If your data is stored locally, then you will probably want to use a `BIDSDataset`, `FolderDataset`, or `CSVDataset`. If your dataset is small enough that you can load all your images into memory at once, then you may want to do that and use a `MemoryDataset`. However, it may be easiest to grab the right data using a `FolderDataset`, for example, and then load all the data into memory - thereby converting it to a `MemoryDataset`.

### FolderDataset

Let's take an example where you have images stored in a folder with a participants data file at the top level:

```
- /dataset
  - participants.csv
  - /sub-001
    - /t1.nii.gz
  - /sub-002
    - /t1.nii.gz
  - /sub-003
    - t1.nii.gz
```

Here is how you would create a dataset with the t1.nii.gz image as input and, say, the age column from participants.tsv as the output:

```python
from nitrain.datasets import FolderDataset

dataset = FolderDataset(base_dir='dataset',
                        x={'pattern': 't1.nii.gz'},
                        y={'file': 'participants.csv', 'column': 'age'})
```

It's that simple. Creating this dataset will map all of the inputs and outputs, but nothing will be actually loaded into memory. You can load data into memory by indexing the dataset.

```python
x, y = dataset[:2]
```

This will give you a list of `antsImage` objects for the `x` variable and a numpy array of age values for the `y` variable.

### BIDSDataset

Creating a `BIDSDataset` is quite similar to a `FolderDataset` except that it is expected for your data to be arranged in BIDS format. The benefit of using BIDS is that you can use so-called "entities" to select the images you want to use in a more structured way.

### CSVDataset

If you have images stored locally in an unstructured way or if you want to select a very unique subset of your images which is not amenable to a glob pattern, then a `CSVDataset` is what you want to use. For this dataset, you pass in a .csv file and identify the columns that you want to use as filepaths or array values for inputs and outputs.

## Specifying multiple inputs or outputs

The examples above demonstrated a simple scenario where our model would take in one image as input and produced a single value as output. In reality, there are more types of input-output combinations. Some examples are as follows:

- single image -> single continuous
- multiple images -> single continuous
- multiple images -> multiple images

To specify more than one input or output, you can pass a list of `x` or `y` dictionaries instead of a single dictionary. Here is what it would look like if we want to provide two images as input and one image as output:

```python
from nitrain.datasets import FolderDataset

dataset = FolderDataset(base_dir='dataset',
                        x=[{'pattern': 't1.nii.gz'}, {'pattern': 't2.nii.gz'}],
                        y={'pattern': 'pet.nii.gz'})
```

Now, if we access this dataset via indexing what we will get for `x` is a list of 2-length lists of images and what we will get for `y` is a list of images.

```python
x, y = dataset[:2]
x[0] # [img1, img2]
```

## Final word on datasets

Your mental model should be that datasets in nitrain are the way to get your images and patient-level data into memory. They are also the way you define what form the inputs and outputs to your model will take. If you want to train a model that takes in two different image modalities as input and outputs a continuous value, datasets are where you start to define such a structure.

Datasets can give you "batches" of images if you want, but the images will not be converted to arrays /tensors. Instead, they will be read into memory, processed using any transforms you provide, and returned as images in a list.

If you have any fixed pre-processing to do on your images (e.g., register them to a template, resample them, etc.) that ideally should be done only once, then you will create transforms that are passed to datasets. No transforms passed to your nitrain dataset should be random / non-deterministic.

### What about frameworks?

You may have noticed that there was no mention of pytorch, keras, or any other framework in this tutorial. That is because datasets operate completely independently of any AI framework. In fact, you can use nitrain datasets to get your data into memory for any type of purpose whether that's training an AI model or performing traditional statistical modelling.
